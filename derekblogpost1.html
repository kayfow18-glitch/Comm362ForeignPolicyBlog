<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Derek's Blog Post One</title>
  <style>
    body {
      margin: 0;
      font-family: 'Georgia', serif;
      line-height: 1.8;
      background-color: #faf9f6;
      color: #222;
    }

    header h1 {
      margin: 0;
      font-size: 2rem;
      text-align: center;
      padding: 1rem;
      background: #0a1a2f;
      color: #fff;
    }

    .post-container {
      max-width: 900px;
      margin: 20px auto;
      padding: 20px;
      background: #fff;
      border-radius: 6px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }

    .post-container h2 {
      text-align: center;
      color: #0a1a2f;
      margin-top: 0;
      border-bottom: 2px solid #c62828;
      padding-bottom: 5px;
      display: table;       /* centers underline with text */
      margin-left: auto;
      margin-right: auto;
    }

    figure {
      max-width: 45%;
      margin: 10px 20px;
    }

    figure img {
      width: 100%;
      border-radius: 6px;
    }

    figure figcaption {
      font-size: 0.8rem;
      color: #555;
      font-style: italic;
      margin-top: 4px;
      text-align: center;
    }

    .img-left {
      float: left;
    }

    .img-right {
      float: right;
    }

    .post-container a {
      color: #c62828;
      font-weight: bold;
      text-decoration: underline;
    }

    .post-container a:hover {
      color: #a61d1d;
    }

    .references {
  clear: both;
  margin-top: 40px;
  padding: 20px 25px;
  background: #f4f4f4;
  border-left: 5px solid #0a1a2f;
  font-size: 0.9rem;
  border-radius: 6px;           /* rounded edges */
  box-shadow: 0 2px 4px rgba(0,0,0,0.1); /* subtle shadow */
}

.references h3 {
  margin-top: 0;
  color: #0a1a2f;
  font-size: 1.3rem;            /* bigger than default */
  font-weight: bold;            /* bolder */
  border-bottom: 2px solid #c62828;
  padding-bottom: 5px;
}

.references ul {
  padding-left: 0;
  list-style: none;             /* remove default bullets */
}

.references ul li {
  margin-bottom: 15px;
  background: #fff;             
  padding: 10px 15px;          /* padding inside box */
  border-radius: 4px;
  box-shadow: 0 1px 2px rgba(0,0,0,0.05);
  text-indent: 0;              /* remove negative indent for safer wrapping */
  word-wrap: break-word;       /* ensures long URLs break */
}


    }

    .references a:hover {
      text-decoration: underline;
    }

    footer {
      background: #0a1a2f;
      color: #ddd;
      text-align: center;
      padding: 1rem;
      margin-top: 30px;
      font-size: 0.9rem;
    }

    .back-button {
      display: inline-block;
      margin-top: 20px;
      padding: 10px 15px;
      background: #c62828;
      color: #fff !important;
      font-size: 16px !important;
      text-decoration: none;
      border-radius: 4px;
      font-weight: bold;
    }

    .back-button:hover {
      background: #a61d1d;
    }
  </style>
</head>
<body>
  <header>
    <h1>Derek's Blog Post One</h1>
  </header>

  <div class="post-container">
    <h2>The Risks of Artificial Intelligence in Warfare</h2>

    <p style="text-align: center;"><em>September 28th, 2025</em></p>

    <p>
    The integration of artificial intelligence (AI) in warfare has posed a significant risk that could negatively impact the future of global security. New advancements in technology are always being used by the military, but as artificial intelligence gets smarter by the day, it is increasingly being used on the battlefield. Some examples of the technologies being used include drones, surveillance systems, and the new AI-powered algorithms being created that enhance military strategy. It is very important to understand the dangers these technologies present and to make sure there is responsible international oversight. The areas of concern that nations need to act on are AI potentially resulting in civilian casualties, the escalations that can occur, cybersecurity risk, and lack of accountability for catastrophic decision-making. Unlike traditional weapons, AI-powered machines can operate independently, making decisions faster than humans ever could, and may be outside human supervision. This can create the possibility of unintended consequences if machines act unpredictably, misinterpret data, or escalate situations. Without meaningful human control, wars could spiral beyond the intentions of world leaders and result in catastrophic consequences.
      <p> 
        
    <p>
      A major risk of AI in warfare is the potential for increased civilian casualties. AI systems rely on algorithms trained on large datasets, but these datasets can be flawed, incomplete, or biased. These systems may struggle to accurately distinguish between legitimate military targets and civilians. This leads to tragic mistakes in densely populated areas. Unlike human soldiers who can apply judgment, empathy, or cultural background/knowledge in complex situations, machines operate strictly on programmed rules. This raises moral and humanitarian concerns.
    </p>

    <p>
     The rapid speed at which AI systems operate creates the danger of escalation in conflict. This increased pace of combat reduces opportunities for negotiations to be reached. It also raises the likelihood of full-scale wars triggered by miscalculations. The existence of AI-powered military systems may lead to incentivizing nations to take on far more aggressive strategies in military operations.
      The use of AI in warfare is also highly vulnerable to cyber threats. There are many concerns about the potential for these systems to malfunction or be hacked. Adversaries could exploit weaknesses in their code or communication networks to manipulate and take over them. There have been recent reports of cyber threats compromising military mobility. “The Cyberspace Solarium Commission 2.0, a successor to the congressionally mandated Cyber Solarium Commission and housed under the Foundation for Defense of Democracies, warned in a Thursday report that air, rail, and maritime networks essential to military mobility are vulnerable to disruption by near-peer adversaries like China.” (Riotta, 2025). This shows that even the most advanced AI-powered systems could become liabilities if compromised by skilled hackers.
      <p>
        
    <p>
      Finally, the use of AI in warfare raises serious questions about accountability and responsibility for when issues occur. Autonomous weapon systems identify, select, and engage without any human intervention. If an autonomous system carries out an unlawful strike, it is not clear where the blame lies. Should the programmers, the military commanders, the government, or the machine be held accountable? These systems can also be used as a shield to deflect personal responsibility. This lack of clarity in who is to blame weakens the norms of international law. AI-driven warfare risks creating a world where there could be excused war crimes and violations of human rights can go unpunished. 
    </p>
    
    <p>
      The ongoing conflict in Ukraine has accelerated the development and deployment of AI-powered systems on the battlefield. Both Ukraine and Russia have leveraged autonomous drones, AI-assisted targeting, and machine learning systems to improve their military effectiveness. Turkish-made Bayraktar TB-2 drones played a major role in strengthening Ukraine’s defenses. This has also exposed the risks of reliance on autonomous systems, with reports of drones misidentifying targets. Analysts compared the rise of AI-based armaments to the nuclear arms race. Unlike nuclear weapons, AI weaponry is cheaper and accessible to more countries, making future wars even more destructive as many nations gain the ability to deploy the same technologies (Yilmaz, Ertürk, Soydemir, Erciyas, & İbrahim, 2023). Other global powers are rapidly developing AI military capabilities. The United States, China, and Russia are leading the charge, investing heavily in AI research. The lack of regulations raises the risk of an AI arms race, where technological advancement takes precedence over ethical responsibility.
      <p>
        
    <p>
      The rise of AI-driven warfare has not gone completely unnoticed despite the seemingly lenient circumstances. The United Nations has taken steps by passing resolutions calling for strict regulations on the development and deployment of autonomous weapons systems (United Nations, 2023). Several European countries have also pushed for bans on lethal autonomous weapons (Smith, 2022). Campaigns such as the “Stop Killer Robots” movement have raised awareness about the ethical dilemmas posed by AI in combat (Campaign to Stop Killer Robots, 2021). These groups are warning against the dangers of allowing machines to make life and death decisions. There is still a need for a global consensus to be reached. 
    </p>
    
    <p>
      The integration of artificial intelligence in warfare leads to many unprecedented risks. The many dangers that are presented cannot be ignored. There is an urgent need for international cooperation and regulation. The responsibility lies with governments, international organizations, and the public society to make sure that technological progress is made to protect, rather than endanger, humanity. The deployment of AI in warfare will likely continue to grow and outpace the ability of regulations to keep up before it is too late.
      </p>

    <div class="references">
  <h3>References</h3>
  <ul>
    <li>U.S. News. (2025, August 15). U.S. aid cuts to Ukraine raise risk of waste and fraud, say watchdogs. <em>U.S. News</em>. <a href="https://www.usnews.com/news/world/articles/2025-08-15/us-aid-cuts-to-ukraine-raise-risk-of-waste-and-fraud-say-watchdogs">Link</a></li>

    <li>Fox News. (2025, September 10). Former ambassador says Ukraine victory key to countering China, Russia. <em>Fox News</em>. <a href="https://www.foxnews.com/world/former-ambassador-says-ukraine-victory-key-countering-china-russia">Link</a></li>

    <li>Fox News. (2025, September 18). Trump pauses aid to Ukraine after fiery meeting with Zelenskyy. <em>Fox News</em>. <a href="https://www.foxnews.com/politics/trump-pauses-aid-ukraine-fiery-meeting-zelenskyy">Link</a></li>
  </ul>
</div>

    <a href="derek.html" class="back-button">← Back to Blog</a>
  </div>

  <footer>
    <p>&copy; 2025 Comm 362 Foreign Policy Blog. All rights reserved.</p>
  </footer>
</body>
</html>
